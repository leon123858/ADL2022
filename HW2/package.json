{
	"name": "hw2",
	"version": "1.0.0",
	"description": "the hw2 for ADL",
	"scripts": {
		"start": "cd report && bash download.sh && bash run.sh './data/context.json' './data/test.json' './cache/pred_result.csv'",
		"clear": "node clear_file.js",
		"format": "autopep8 --in-place --recursive .",
		"freeze": "conda list -e > conda_requirements.txt && pip freeze > pip_requirements.txt",
		"preprocess": "cd src && python preprocess.py",
		"postprocess": "cd src && python postprocess.py",
		"middleprocess": "cd src && python middleprocess.py",
		"train_select": "cd src && python train_select.py --max_seq_length=512 --pad_to_max_length --train_file='../cache/train_select_data.json' --validation_file='../cache/valid_select_data.json' --model_name_or_path ckiplab/bert-base-chinese --tokenizer_name bert-base-chinese --do_train --do_eval --learning_rate 5e-5 --num_train_epochs 1 --output_dir ./tmp --per_gpu_eval_batch_size=2 --per_device_train_batch_size=2 --gradient_accumulation_steps=2 --overwrite_output",
		"train_answer": "cd src/answerlib/ && python run_qa.py --max_seq_length=512 --pad_to_max_length --train_file='../../cache/train_answer_data.json' --validation_file='../../cache/valid_answer_data.json' --model_name_or_path ckiplab/bert-base-chinese --tokenizer_name bert-base-chinese --do_train --do_eval --learning_rate 3e-5 --num_train_epochs 1 --output_dir ./tmp --per_device_train_batch_size=2 --doc_stride 128 --gradient_accumulation_steps=2",
		"train_select2": "cd src && python train_select.py --max_seq_length=512 --pad_to_max_length --train_file='../cache/train_select_data.json' --validation_file='../cache/valid_select_data.json' --model_name_or_path ckiplab/albert-tiny-chinese --tokenizer_name bert-base-chinese --do_train --do_eval --learning_rate 5e-5 --num_train_epochs 3 --output_dir ./tmp --per_gpu_eval_batch_size=8 --per_device_train_batch_size=8 --gradient_accumulation_steps=2 --overwrite_output",
		"train_answer2": "cd src/answerlib/ && python run_qa.py --max_seq_length=512 --pad_to_max_length --train_file='../../cache/train_answer_data.json' --validation_file='../../cache/valid_answer_data.json' --model_name_or_path hfl/chinese-roberta-wwm-ext --tokenizer_name bert-base-chinese --do_train --do_eval --learning_rate 3e-5 --num_train_epochs 6 --output_dir ./tmp --per_device_train_batch_size=8 --doc_stride 128 --gradient_accumulation_steps=2",
		"pred_select": "cd src && python train_select.py --max_seq_length=512 --pad_to_max_length --model_name_or_path='./model/basic-select' --tokenizer_name bert-base-chinese --do_predict --prediction_file='../data/test.json' --output_dir ./tmp --per_gpu_eval_batch_size=2 --per_device_train_batch_size=8 --overwrite_output",
		"pred_answer": "cd src/answerlib/ && python run_qa.py --max_seq_length=512 --pad_to_max_length --model_name_or_path='../model/basic-answer' --tokenizer_name bert-base-chinese --do_predict --test_file='../../cache/middle_test_result.json' --output_dir ./tmp --per_gpu_eval_batch_size=2 --per_device_train_batch_size=8",
		"pred_select2": "cd src && python train_select.py --max_seq_length=512 --pad_to_max_length --model_name_or_path='./model/basic-select' --tokenizer_name bert-base-chinese --do_predict --prediction_file='../data/test.json' --output_dir ./tmp --per_gpu_eval_batch_size=2 --per_device_train_batch_size=2 --overwrite_output",
		"pred_answer2": "cd src/answerlib/ && python run_qa.py --max_seq_length=512 --pad_to_max_length --model_name_or_path='../model/advance-answer' --tokenizer_name bert-base-chinese --do_predict --test_file='../../cache/middle_test_result.json' --output_dir ./tmp --per_gpu_eval_batch_size=2 --per_device_train_batch_size=2",
		"test": "bash src/test.sh",
		"train2": "yarn train_select2 && yarn train_answer2",
		"retrain": "cd src/answerlib/ && python run_qa.py --max_seq_length=512 --pad_to_max_length --train_file='../../cache/train_answer_data.json' --validation_file='../../cache/valid_answer_data.json' --model_name_or_path='../model/basic-answer' --tokenizer_name bert-base-chinese --do_train --do_eval --learning_rate 3e-5 --num_train_epochs 2 --output_dir ./tmp --per_device_train_batch_size=8 --doc_stride 128 --gradient_accumulation_steps=2 --overwrite_output_dir",
		"train_slot": "cd src/bonus/ && python train_slot.py --text_column_name 'tokens' --label_column_name 'tags' --model_name_or_path bert-base-uncased --train_file ./slot/train.json --validation_file ./slot/eval.json --output_dir ./tmp --do_train --do_eval"
	},
	"author": "Leon Lin",
	"license": "ISC",
	"dependencies": {
		"del": "^7.0.0"
	}
}
